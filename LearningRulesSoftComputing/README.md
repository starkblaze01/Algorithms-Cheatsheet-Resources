# Learning Rules

## Delta Learning
- The **Delta Rule** uses the difference between _target activation_ (i.e., target output values) and _obtained activation_ to drive learning
- It is a [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent "Gradient descent") learning rule for updating the weights of the inputs to [artificial neurons](https://en.wikipedia.org/wiki/Artificial_neurons "Artificial neurons") in a [single-layer neural network](https://en.wikipedia.org/wiki/Feedforward_neural_network#Single-layer_perceptron "Feedforward neural network").
- You can learn more about it [here](https://medium.com/@neuralnets/delta-learning-rule-gradient-descent-neural-networks-f880c168a804).

## Perceptron Learning
- The perceptron model is a more general computational model than McCulloch-Pitts neuron.
- You can learn more about it [here](https://towardsdatascience.com/perceptron-learning-algorithm-d5db0deab975).